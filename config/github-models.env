# GitHub Models Configuration via liteLLM
# ========================================

# GitHub Models API Configuration
GITHUB_TOKEN=your-github-token-here
GITHUB_MODELS_API_BASE=https://models.inference.ai.azure.com

# liteLLM Proxy Configuration
LITELLM_PORT=8083
LITELLM_HOST=localhost
LITELLM_BASE_URL=http://localhost:8083

# Model Mapping for Claude Code
# These will be used when Claude Code requests haiku/sonnet models
GITHUB_BIG_MODEL=gpt-4o  # Maps to Claude Sonnet requests
GITHUB_SMALL_MODEL=gpt-4o-mini  # Maps to Claude Haiku requests

# Available GitHub Models (examples)
# AI21Labs/Jamba-1.5-Large
# AI21Labs/Jamba-1.5-Mini  
# Cohere/Cohere-command-r-plus
# Cohere/Cohere-command-r-plus-08-2024
# Meta/Llama-3.2-11B-Vision-Instruct
# Meta/Llama-3.2-90B-Vision-Instruct
# Microsoft/Phi-3-medium-128k-instruct
# Microsoft/Phi-3-medium-4k-instruct
# Microsoft/Phi-3-mini-128k-instruct
# Microsoft/Phi-3-mini-4k-instruct
# Microsoft/Phi-3-small-128k-instruct
# Microsoft/Phi-3-small-8k-instruct
# OpenAI/gpt-4o
# OpenAI/gpt-4o-mini
# mistralai/Mistral-large
# mistralai/Mistral-large-2407
# mistralai/Mistral-Nemo
# mistralai/Mistral-small

# Rate Limiting
GITHUB_MODELS_MAX_REQUESTS_PER_MINUTE=60
GITHUB_MODELS_MAX_TOKENS_PER_MINUTE=50000

# Cost Tracking
ENABLE_GITHUB_MODELS_COST_TRACKING=true
GITHUB_MODELS_COST_LOG_FILE=/tmp/github-models-usage.log

# Debug and Logging
LITELLM_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
GITHUB_MODELS_DEBUG=false

# Fallback Configuration
ENABLE_GITHUB_MODELS_FALLBACK=true
GITHUB_MODELS_FALLBACK_MODEL=gpt-4o-mini